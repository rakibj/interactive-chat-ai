{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f817fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\PC/.cache\\torch\\hub\\snakers4_silero-vad_master\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "from faster_whisper import WhisperModel\n",
    "import time\n",
    "from collections import deque\n",
    "import threading\n",
    "import torch\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import json\n",
    "\n",
    "TRANSCRIPTION_MODE = \"vosk\"  \n",
    "# options: \"vosk\", \"whisper\"\n",
    "\n",
    "vad_model, vad_utils = torch.hub.load(\n",
    "    repo_or_dir = \"snakers4/silero-vad\",\n",
    "    model = \"silero_vad\",\n",
    "    force_reload = False\n",
    ")\n",
    "\n",
    "(get_speech_timestamps, save_audio, read_audio, VADIterator, collect_chunks) = vad_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "627a92f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "audio_buffer = []\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    audio_buffer.append(indata.copy())\n",
    "\n",
    "stream = sd.InputStream(\n",
    "    samplerate=SAMPLE_RATE, \n",
    "    channels=1,\n",
    "    callback=audio_callback\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afafef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_iterator = VADIterator(vad_model)\n",
    "\n",
    "silence_ms = 0\n",
    "is_user_speaking = False\n",
    "\n",
    "def process_vad(chunk):\n",
    "    global silence_ms, is_user_speaking\n",
    "\n",
    "    speech_prob = vad_iterator(chunk, SAMPLE_RATE)\n",
    "\n",
    "    if speech_prob > 0.5:\n",
    "        silence_ms = 0\n",
    "        is_user_speaking = True\n",
    "    else:\n",
    "        silence_ms += int(len(chunk) / SAMPLE_RATE * 1000)\n",
    "        if silence_ms > 800:\n",
    "            is_user_speaking = False\n",
    "\n",
    "    return is_user_speaking, silence_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e576f822",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "whisper = None\n",
    "\n",
    "if TRANSCRIPTION_MODE == \"whisper\":\n",
    "    whisper = WhisperModel(\n",
    "        \"small\",\n",
    "        device=\"cpu\",\n",
    "        compute_type=\"int8\"\n",
    "    )\n",
    "\n",
    "WHISPER_WINDOW_SEC = 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbf7fb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASR mode: vosk\n"
     ]
    }
   ],
   "source": [
    "vosk_model = None\n",
    "vosk_rec = None\n",
    "VOSK_MIN_SAMPLES = 3200  # 0.2 sec @ 16kHz\n",
    "\n",
    "\n",
    "if TRANSCRIPTION_MODE == \"vosk\":\n",
    "    vosk_model = Model(\"models/vosk-model-small-en-us-0.15\")\n",
    "    vosk_rec = KaldiRecognizer(vosk_model, 16000)\n",
    "    vosk_rec.SetWords(True)\n",
    "\n",
    "print(f\"ASR mode: {TRANSCRIPTION_MODE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a53ddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_audio = deque()\n",
    "asr_lock = threading.Lock()\n",
    "current_partial_text = \"\"\n",
    "vosk_reset_requested = False\n",
    "\n",
    "def float32_to_int16(audio):\n",
    "    audio = np.clip(audio, -1.0, 1.0)\n",
    "    return (audio * 32767).astype(np.int16)\n",
    "\n",
    "def asr_worker():\n",
    "    global current_partial_text\n",
    "    global vosk_reset_requested\n",
    "\n",
    "    if TRANSCRIPTION_MODE == \"whisper\":\n",
    "        # ---------- WHISPER MODE ----------\n",
    "        while True:\n",
    "            time.sleep(0.7)\n",
    "\n",
    "            with asr_lock:\n",
    "                if not asr_audio:\n",
    "                    continue\n",
    "\n",
    "                now = time.time()\n",
    "                recent = [\n",
    "                    frame for frame, t in asr_audio\n",
    "                    if now - t <= WHISPER_WINDOW_SEC\n",
    "                ]\n",
    "\n",
    "            if not recent:\n",
    "                continue\n",
    "\n",
    "            audio_np = np.concatenate(recent)\n",
    "\n",
    "            segments, _ = whisper.transcribe(\n",
    "                audio_np,\n",
    "                language=\"en\",\n",
    "                vad_filter=False,\n",
    "                beam_size=1,\n",
    "                temperature=0.0\n",
    "            )\n",
    "\n",
    "            text = \" \".join(seg.text for seg in segments).strip()\n",
    "            if text and text != current_partial_text:\n",
    "                current_partial_text = text\n",
    "                print(\"ğŸ“ Partial:\", text)\n",
    "\n",
    "    else:\n",
    "        if vosk_reset_requested:\n",
    "            vosk_rec.Reset()\n",
    "            vosk_reset_requested = False\n",
    "            current_partial_text = \"\"\n",
    "        # ---------- VOSK MODE ----------\n",
    "        while True:\n",
    "            time.sleep(0.05)\n",
    "\n",
    "            with asr_lock:\n",
    "                if not asr_audio:\n",
    "                    continue\n",
    "\n",
    "                frame, _ = asr_audio.popleft()\n",
    "                if len(frame) < VOSK_MIN_SAMPLES:\n",
    "                    continue\n",
    "                pcm16 = float32_to_int16(frame)\n",
    "\n",
    "            try:\n",
    "                is_final = vosk_rec.AcceptWaveform(pcm16.tobytes())\n",
    "            except Exception:\n",
    "                continue  # drop bad frame safely\n",
    "            \n",
    "            if vosk_rec.AcceptWaveform(pcm16.tobytes()):\n",
    "                res = json.loads(vosk_rec.Result())\n",
    "                text = res.get(\"text\", \"\").strip()\n",
    "                if text:\n",
    "                    print(\"ğŸ“ Final:\", text)\n",
    "                    current_partial_text = \"\"\n",
    "            else:\n",
    "                res = json.loads(vosk_rec.PartialResult())\n",
    "                partial = res.get(\"partial\", \"\").strip()\n",
    "                if partial and partial != current_partial_text:\n",
    "                    current_partial_text = partial\n",
    "                    print(\"ğŸ“ Partial:\", partial)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a5cb7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asr worker started\n"
     ]
    }
   ],
   "source": [
    "threading.Thread(\n",
    "    target=asr_worker,\n",
    "    daemon=True\n",
    ").start()\n",
    "\n",
    "print(\"Asr worker started\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "089cd79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- ANALYSIS BUFFERS --------\n",
    "energy_history = deque(maxlen=15)       # RMS history (~300ms)\n",
    "pause_history = deque(maxlen=5)          # pause lengths within turn\n",
    "micro_spike_times = deque(maxlen=5)      # small resumption attempts\n",
    "\n",
    "last_ai_interrupted = False\n",
    "TRAILING_CONJUNCTIONS = {\n",
    "    \"and\",\"or\",\"but\",\"because\",\"so\",\"that\",\"which\",\"who\",\n",
    "    \"when\",\"if\",\"though\",\"while\"\n",
    "}\n",
    "\n",
    "OPEN_ENDED_PREFIXES = (\n",
    "    \"i think\",\"i guess\",\"i'm not sure\",\"the thing is\",\"it depends\"\n",
    ")\n",
    "\n",
    "QUESTION_LEADINS = (\n",
    "    \"do you think\",\"would you say\",\"is it possible\",\"can you\"\n",
    ")\n",
    "\n",
    "SELF_REPAIR_MARKERS = (\n",
    "    \"i mean\",\"actually\",\"sorry\",\"no wait\"\n",
    ")\n",
    "\n",
    "FILLER_ENDINGS = (\n",
    "    \"uh\",\"um\",\"like\",\"you know\",\"kind of\"\n",
    ")\n",
    "\n",
    "def lexical_bias(text: str) -> float:\n",
    "    if not text:\n",
    "        return 0.0\n",
    "\n",
    "    t = text.lower().strip()\n",
    "    words = t.split()\n",
    "\n",
    "    score = 0.0\n",
    "\n",
    "    # 6ï¸âƒ£ trailing conjunction blocker\n",
    "    if words[-1] in TRAILING_CONJUNCTIONS:\n",
    "        score -= 1.0\n",
    "\n",
    "    # 7ï¸âƒ£ open-ended phrases\n",
    "    if any(t.startswith(p) for p in OPEN_ENDED_PREFIXES):\n",
    "        score -= 0.6\n",
    "\n",
    "    # 8ï¸âƒ£ question lead-ins\n",
    "    if any(t.startswith(q) for q in QUESTION_LEADINS):\n",
    "        score -= 0.5\n",
    "\n",
    "    # 9ï¸âƒ£ self-repair markers\n",
    "    if any(m in t[-20:] for m in SELF_REPAIR_MARKERS):\n",
    "        score -= 0.4\n",
    "\n",
    "    # ğŸ”Ÿ filler ending guard\n",
    "    if words[-1] in FILLER_ENDINGS:\n",
    "        score -= 0.7\n",
    "\n",
    "    return score\n",
    "\n",
    "def energy_decay_score():\n",
    "    if len(energy_history) < 5:\n",
    "        return 0.0\n",
    "    x = np.arange(len(energy_history))\n",
    "    y = np.array(energy_history)\n",
    "    slope = np.polyfit(x, y, 1)[0]\n",
    "    return 0.8 if slope < -0.00015 else 0.0\n",
    "\n",
    "def micro_resumption_penalty(now, elapsed):\n",
    "    if elapsed > 900:      # late pause â†’ ignore micro-resumptions\n",
    "        return 0.0\n",
    "    recent = [t for t in micro_spike_times if now - t < 0.8]\n",
    "    return -0.6 if len(recent) >= 2 else 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20b88039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ™ï¸ Real-time conversation test started\n",
      "ğŸŸ¢ Speech started\n",
      "ğŸ“ Partial: hey\n",
      "ğŸŸ¡ Pause 606 ms\n",
      "ğŸ“ Final: hey\n",
      "ğŸŸ¢ Speech resumed\n",
      "ğŸ“ Partial: andre andre\n",
      "ğŸ“ Partial: andre andre don't\n",
      "ğŸ“ Partial: andre andre don't understand\n",
      "ğŸ“ Partial: andre andre don't understand if\n",
      "ğŸ“ Partial: andre andre don't understand and empathize\n",
      "ğŸ“ Partial: andre andre don't understand if if if if if\n",
      "ğŸ“ Partial: andre andre don't understand if if if if\n",
      "ğŸ“ Partial: andre andre don't understand if if if if it\n",
      "ğŸ“ Partial: andre andre don't understand if if if if you are working\n",
      "ğŸ“ Partial: andre andre don't understand if if if if you are working world\n",
      "ğŸ“ Partial: andre andre don't understand if if if if you are working world will\n",
      "ğŸŸ¡ Pause 620 ms\n",
      "ğŸ“ Final: andre andre don't own under threat and if if if if it is working very well\n",
      "ğŸ”´ Turn ended (confidence=1.70, silence=1221ms)\n",
      "ğŸŸ¢ Speech started\n",
      "ğŸ“ Partial: see\n",
      "ğŸ“ Partial: see them\n",
      "ğŸ“ Partial: see them that\n",
      "ğŸŸ¡ Pause 604 ms\n",
      "ğŸ“ Final: see than that\n",
      "ğŸŸ¢ Speech resumed\n",
      "ğŸ“ Partial: the the\n",
      "ğŸ“ Partial: the the data\n",
      "ğŸ“ Partial: the the down and\n",
      "ğŸ“ Partial: the the down and was\n",
      "ğŸ“ Final: the that the down and was was\n",
      "ğŸ“ Partial: in any\n",
      "ğŸ“ Partial: an end and\n",
      "ğŸ“ Partial: an end in the good\n",
      "ğŸ“ Partial: an end in the last\n",
      "ğŸ“ Partial: an end in the last time\n",
      "ğŸ“ Final: an end in the last time\n",
      "ğŸŸ¡ Pause 602 ms\n",
      "ğŸŸ¢ Speech resumed\n",
      "ğŸ“ Partial: birnbaum\n",
      "ğŸ“ Final: there\n",
      "ğŸŸ¡ Pause 600 ms\n",
      "ğŸ”´ Turn ended (confidence=1.70, silence=1200ms)\n",
      "ğŸŸ¢ Speech started\n",
      "ğŸ“ Partial: researchers\n",
      "ğŸ“ Partial: nurture your\n",
      "ğŸ“ Partial: but cheerier\n",
      "ğŸŸ¡ Pause 602 ms\n",
      "ğŸ“ Final: merci cheerier\n",
      "ğŸ”´ Turn ended (confidence=1.70, silence=1205ms)\n",
      "ğŸŸ¢ Speech started\n",
      "ğŸ“ Partial: stand in the\n",
      "ğŸŸ¡ Pause 626 ms\n",
      "ğŸ“ Final: stand in the eat\n",
      "ğŸŸ¢ Speech resumed\n",
      "ğŸ“ Partial: started in\n",
      "ğŸ“ Partial: started\n",
      "ğŸ“ Partial: started in the world\n",
      "ğŸ“ Final: started in the world\n",
      "ğŸŸ¡ Pause 651 ms\n",
      "ğŸŸ¢ Speech resumed\n",
      "ğŸ“ Partial: but\n",
      "ğŸŸ¡ Pause 600 ms\n",
      "ğŸ“ Final: but\n",
      "ğŸŸ¢ Speech resumed\n",
      "ğŸ“ Partial: i do i do\n",
      "ğŸ“ Partial: i do i don't see\n",
      "ğŸ“ Partial: i do i do see the\n",
      "ğŸ“ Partial: i do i do see the that\n",
      "ğŸ“ Final: i do i do see the that\n",
      "ğŸŸ¡ Pause 630 ms\n",
      "ğŸŸ¢ Speech resumed\n",
      "ğŸ“ Partial: at\n",
      "ğŸ“ Partial: at what\n",
      "ğŸŸ¡ Pause 645 ms\n",
      "ğŸ“ Partial: at what one\n",
      "ğŸŸ¢ Speech resumed\n",
      "ğŸ“ Partial: at what one point eight\n",
      "ğŸ“ Partial: at what one point he did\n",
      "ğŸŸ¡ Pause 627 ms\n",
      "ğŸ“ Final: at what one point he did\n",
      "ğŸŸ¢ Speech resumed\n",
      "ğŸ“ Partial: startup\n",
      "ğŸ“ Final: startup\n",
      "ğŸŸ¡ Pause 627 ms\n",
      "ğŸ”´ Turn ended (confidence=1.70, silence=1224ms)\n",
      "ğŸ“ Partial: the\n",
      "ğŸŸ¢ Speech started\n",
      "ğŸ“ Partial: the be people\n",
      "ğŸ“ Partial: the be people but\n",
      "ğŸ“ Partial: the be people but this is\n",
      "ğŸ“ Partial: the be people but this is is\n",
      "ğŸ“ Final: the be people but this is is is you this\n",
      "ğŸ“ Partial: no no\n",
      "ğŸ“ Partial: no not that bad\n",
      "ğŸ“ Partial: no not that bad and\n",
      "ğŸ“ Partial: no not that bad at\n",
      "ğŸŸ¡ Pause 622 ms\n",
      "ğŸ“ Final: no not that bad and\n",
      "ğŸ”´ Turn ended (confidence=1.70, silence=1226ms)\n",
      "ğŸŸ¢ Speech started\n",
      "ğŸ“ Partial: setting\n",
      "ğŸ“ Partial: testing than that\n",
      "ğŸ“ Partial: testing than that that\n",
      "ğŸ“ Final: testing than that that\n",
      "ğŸŸ¡ Pause 630 ms\n",
      "ğŸ”´ Turn ended (confidence=1.70, silence=1201ms)\n",
      "ğŸŸ¢ Speech started\n",
      "ğŸ“ Partial: there's there's\n",
      "ğŸ“ Partial: this is not known\n",
      "ğŸ“ Partial: this is not known better\n",
      "ğŸ“ Partial: this is not not bad at\n",
      "ğŸ“ Final: this is not known been bad and\n",
      "ğŸŸ¡ Pause 623 ms\n",
      "ğŸ”´ Turn ended (confidence=1.70, silence=1202ms)\n",
      "ğŸŸ¢ Speech started\n",
      "ğŸ“ Partial: all\n",
      "ğŸ“ Partial: the thing that\n",
      "ğŸ“ Partial: the thing than that\n",
      "ğŸ“ Partial: the thing then that he did\n",
      "ğŸ“ Final: all the thing then that he added\n",
      "ğŸŸ¡ Pause 603 ms\n",
      "ğŸŸ¢ Speech resumed\n",
      "ğŸ“ Partial: made me\n",
      "ğŸ“ Final: made me\n",
      "ğŸŸ¡ Pause 606 ms\n",
      "ğŸŸ¢ Speech resumed\n",
      "ğŸ“ Partial: good good\n",
      "ğŸ“ Partial: get get it up\n",
      "ğŸ“ Partial: get get it up the\n",
      "ğŸ“ Partial: get get it up the between\n",
      "ğŸ“ Partial: get get it up the be\n",
      "ğŸ“ Partial: get get it up the be more\n",
      "ğŸŸ¡ Pause 601 ms\n",
      "ğŸ“ Final: get get it up that be more\n",
      "ğŸŸ¢ Speech resumed\n",
      "ğŸ“ Partial: better\n",
      "ğŸ“ Partial: better jones\n",
      "ğŸ“ Partial: better and is\n",
      "ğŸ“ Partial: better jones understand and\n",
      "ğŸ“ Partial: better jones understand and dating\n",
      "ğŸŸ¡ Pause 601 ms\n",
      "ğŸ“ Final: better jones understand and dating\n",
      "ğŸŸ¢ Speech resumed\n",
      "ğŸ“ Partial: sam\n",
      "ğŸ“ Partial: salmon is\n",
      "ğŸ“ Partial: sam spade\n",
      "ğŸ“ Partial: sam analysts\n",
      "ğŸ“ Partial: sam analysts bags\n",
      "ğŸ“ Final: sam analysts bags\n",
      "ğŸŸ¡ Pause 623 ms\n",
      "ğŸ”´ Turn ended (confidence=1.70, silence=1237ms)\n",
      "ğŸŸ¢ Speech started\n",
      "ğŸ“ Partial: just as\n",
      "ğŸ“ Partial: just decision\n",
      "ğŸ“ Partial: just definition\n",
      "ğŸ“ Final: just decision\n",
      "ğŸ“ Partial: he\n",
      "ğŸ“ Partial: the\n",
      "ğŸ“ Partial: in in\n",
      "ğŸ“ Partial: the in intending\n",
      "ğŸ“ Partial: in in dating a\n",
      "ğŸ“ Partial: in in dating it\n",
      "ğŸ“ Partial: in in dating a bit what\n",
      "ğŸ“ Partial: in in dating a bit what will work\n",
      "ğŸ“ Partial: in in dating it went well aware\n",
      "ğŸ“ Partial: in in dating it went well aware of\n",
      "ğŸ“ Partial: in in dating it went well aware of the day and\n",
      "ğŸ“ Partial: in in dating it went well aware that they don't have as\n",
      "ğŸ“ Partial: in in dating it went well aware that they don't have a\n",
      "ğŸ“ Partial: in in dating it went well aware that they don't have as\n",
      "ğŸ“ Final: the in in dating a it what well where where they they don't have as assassin\n",
      "ğŸŸ¡ Pause 600 ms\n",
      "ğŸŸ¢ Speech resumed\n",
      "ğŸ“ Partial: the\n",
      "ğŸ“ Partial: that\n",
      "ğŸ“ Partial: that that's acceptable\n",
      "ğŸ“ Partial: that that's something that\n",
      "ğŸ“ Partial: that that's something that in their\n",
      "ğŸ“ Partial: that that's something that was good\n",
      "ğŸ“ Partial: that that's something that's as good as\n",
      "ğŸ“ Partial: that that's something that's as good as i said\n",
      "ğŸ“ Partial: that that's something that's as good as are certain\n",
      "ğŸ“ Final: that that's that's something that's as good as are it\n",
      "ğŸŸ¡ Pause 613 ms\n",
      "ğŸŸ¢ Speech resumed\n",
      "ğŸ“ Partial: in the coming\n",
      "ğŸ“ Partial: in the coming in\n",
      "ğŸ“ Partial: in the coming in that\n",
      "ğŸ“ Partial: in the coming in that at it\n",
      "ğŸ“ Partial: in the coming in that it is is\n",
      "ğŸ“ Partial: in the coming in that it is is at\n",
      "ğŸ“ Partial: in the coming in that it is is at absolutely\n",
      "ğŸ“ Partial: in the coming in that it is is at absolutely spot on\n",
      "ğŸ“ Final: in the coming in that at it easy is at abs absolutely spot on\n",
      "ğŸŸ¡ Pause 619 ms\n",
      "ğŸ”´ Turn ended (confidence=1.70, silence=1216ms)\n",
      "ğŸŸ¢ Speech started\n",
      "ğŸ“ Partial: let let's see\n",
      "ğŸ“ Partial: let let's see see\n",
      "ğŸ“ Partial: let let's see see a\n",
      "ğŸ“ Partial: let let's see see how\n",
      "ğŸ“ Partial: let let's see see how it would\n",
      "ğŸ“ Partial: let let's see see how it with\n",
      "ğŸ“ Partial: let let's see see how read the data\n",
      "ğŸ“ Partial: let let's see see how it with that allows us\n",
      "ğŸŸ¡ Pause 650 ms\n",
      "ğŸ“ Final: let let's see see how it with that allows us\n",
      "ğŸŸ¢ Speech resumed\n",
      "ğŸ“ Partial: when i\n",
      "ğŸ“ Partial: when i'm\n",
      "ğŸ“ Partial: where am i an eye on him\n",
      "ğŸŸ¡ Pause 628 ms\n",
      "ğŸ“ Final: where am i an eye on him\n",
      "ğŸŸ¢ Speech resumed\n",
      "ğŸ“ Partial: but\n",
      "ğŸ“ Partial: but between\n",
      "ğŸŸ¡ Pause 652 ms\n",
      "ğŸ“ Final: but between\n",
      "ğŸŸ¢ Speech resumed\n",
      "ğŸ“ Partial: as\n",
      "ğŸ“ Partial: as a sense into\n",
      "ğŸ“ Partial: as a sense intended sand\n",
      "ğŸ“ Partial: as a sense and intense as an\n",
      "ğŸ“ Partial: as a sense and intense as and rendering\n",
      "ğŸ“ Partial: as a sense and intense as and rendering to do\n",
      "ğŸ“ Final: as a sense and intense as and rendering to do\n",
      "ğŸ“ Partial: an\n",
      "ğŸ“ Partial: and into\n",
      "ğŸ“ Partial: and into citizen\n",
      "ğŸ“ Partial: and into citizen dungeons and\n",
      "ğŸ“ Partial: and indices and and infants\n",
      "ğŸ“ Final: and endless isn't and infants\n",
      "ğŸŸ¡ Pause 631 ms\n",
      "ğŸ”´ Turn ended (confidence=1.70, silence=1208ms)\n",
      "\n",
      "ğŸ›‘ Test stopped\n"
     ]
    }
   ],
   "source": [
    "# --------\n",
    "# REAL-TIME TURN-TAKING ENGINE (FIXED)\n",
    "# --------\n",
    "\n",
    "# -------- CONFIG --------\n",
    "VAD_MIN_SAMPLES = 512\n",
    "PAUSE_MS = 600\n",
    "END_MS = 1200\n",
    "SAFETY_TIMEOUT_MS = 2500  # Critical fallback\n",
    "ENERGY_FLOOR = 0.015      # Increased to ignore mic noise\n",
    "WHISPER_WINDOW_SEC = 3.0\n",
    "CONFIDENCE_THRESHOLD = 1.2  # Reduced from 1.8\n",
    "\n",
    "# -------- STATE --------\n",
    "state = \"IDLE\"              # IDLE | SPEAKING | PAUSING\n",
    "last_voice_time = None\n",
    "last_ai_interrupted = False\n",
    "current_partial_text = \"\"\n",
    "vosk_reset_requested = False\n",
    "\n",
    "# Buffers\n",
    "vad_buffer = np.zeros(0, dtype=np.float32)\n",
    "energy_history = deque(maxlen=15)\n",
    "pause_history = deque(maxlen=5)\n",
    "micro_spike_times = deque(maxlen=5)\n",
    "\n",
    "stream.start()\n",
    "print(\"ğŸ™ï¸ Real-time conversation test started\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        if not audio_buffer:\n",
    "            time.sleep(0.01)\n",
    "            continue\n",
    "\n",
    "        # ---- collect audio ----\n",
    "        chunk = audio_buffer.pop(0).astype(np.float32).flatten()\n",
    "        vad_buffer = np.concatenate([vad_buffer, chunk])\n",
    "\n",
    "        if len(vad_buffer) < VAD_MIN_SAMPLES:\n",
    "            continue\n",
    "\n",
    "        frame = vad_buffer[:VAD_MIN_SAMPLES]\n",
    "        vad_buffer = vad_buffer[VAD_MIN_SAMPLES:]\n",
    "\n",
    "        if len(frame) < VAD_MIN_SAMPLES:\n",
    "            continue\n",
    "\n",
    "        now = time.time()\n",
    "        rms = np.sqrt(np.mean(frame ** 2))\n",
    "        energy_history.append(rms)\n",
    "\n",
    "        # ---- CORRECT REAL-TIME VAD ----\n",
    "        # Use raw model output (probability), NOT VADIterator\n",
    "        with torch.no_grad():\n",
    "            vad_confidence = vad_model(\n",
    "                torch.from_numpy(frame).unsqueeze(0),\n",
    "                16000\n",
    "            ).item()\n",
    "        speech_started = vad_confidence > 0.5\n",
    "\n",
    "        # Sustained voice: at least 3 of last 15 frames above floor\n",
    "        sustained = sum(e > ENERGY_FLOOR for e in energy_history) >= 3\n",
    "\n",
    "        # ---- MICRO-SPIKE DETECTION (for PAUSING state) ----\n",
    "        if state == \"PAUSING\" and rms > ENERGY_FLOOR:\n",
    "            micro_spike_times.append(now)\n",
    "\n",
    "        # ---- STATE MACHINE ----\n",
    "        if state == \"IDLE\":\n",
    "            if speech_started or sustained:\n",
    "                state = \"SPEAKING\"\n",
    "                last_voice_time = now\n",
    "                print(\"ğŸŸ¢ Speech started\")\n",
    "\n",
    "        elif state == \"SPEAKING\":\n",
    "            if speech_started or sustained:\n",
    "                last_voice_time = now\n",
    "            else:\n",
    "                elapsed = (now - last_voice_time) * 1000\n",
    "                if elapsed >= PAUSE_MS:\n",
    "                    state = \"PAUSING\"\n",
    "                    print(f\"ğŸŸ¡ Pause {int(elapsed)} ms\")\n",
    "\n",
    "        elif state == \"PAUSING\":\n",
    "            elapsed = (now - last_voice_time) * 1000\n",
    "\n",
    "            # ğŸ”¥ SAFETY TIMEOUT: Always end turn after 2.5s silence\n",
    "            if elapsed > SAFETY_TIMEOUT_MS:\n",
    "                print(f\"ğŸ”´ SAFETY TIMEOUT: Force-ending turn after {elapsed:.0f}ms\")\n",
    "                state = \"IDLE\"\n",
    "                last_voice_time = None\n",
    "                energy_history.clear()\n",
    "                pause_history.clear()\n",
    "                micro_spike_times.clear()\n",
    "                last_ai_interrupted = False\n",
    "                with asr_lock:\n",
    "                    asr_audio.clear()\n",
    "                current_partial_text = \"\"\n",
    "                if TRANSCRIPTION_MODE == \"vosk\":\n",
    "                    vosk_reset_requested = True\n",
    "                continue\n",
    "\n",
    "            # Resume speech?\n",
    "            if speech_started or sustained:\n",
    "                state = \"SPEAKING\"\n",
    "                last_voice_time = now\n",
    "                print(\"ğŸŸ¢ Speech resumed\")\n",
    "            else:\n",
    "                # Calculate turn-end confidence\n",
    "                confidence = 0.0\n",
    "\n",
    "                # 1. Silence duration\n",
    "                if elapsed > END_MS:\n",
    "                    confidence += 1.0\n",
    "\n",
    "                # 2. Energy decay (consistently low energy)\n",
    "                if len(energy_history) >= 8:\n",
    "                    recent_energies = list(energy_history)[-8:]  # last ~160ms\n",
    "                    if max(recent_energies) < ENERGY_FLOOR * 1.8:\n",
    "                        confidence += 0.7\n",
    "\n",
    "                # 3. Micro-resumption penalty (only for short pauses)\n",
    "                if elapsed < 1000:\n",
    "                    recent_spikes = [t for t in micro_spike_times if now - t < 0.6]\n",
    "                    if len(recent_spikes) >= 2:\n",
    "                        confidence -= 0.5\n",
    "\n",
    "                # 4. Lexical bias (only block early endings)\n",
    "                if elapsed < 900 and current_partial_text:\n",
    "                    confidence += lexical_bias(current_partial_text) * 0.6\n",
    "\n",
    "                # 5. Interruption memory\n",
    "                if last_ai_interrupted:\n",
    "                    confidence -= 0.5\n",
    "\n",
    "                # End turn?\n",
    "                if confidence >= CONFIDENCE_THRESHOLD:\n",
    "                    print(f\"ğŸ”´ Turn ended (confidence={confidence:.2f}, silence={elapsed:.0f}ms)\")\n",
    "                    state = \"IDLE\"\n",
    "                    last_voice_time = None\n",
    "                    energy_history.clear()\n",
    "                    pause_history.clear()\n",
    "                    micro_spike_times.clear()\n",
    "                    last_ai_interrupted = False\n",
    "                    with asr_lock:\n",
    "                        asr_audio.clear()\n",
    "                    current_partial_text = \"\"\n",
    "                    if TRANSCRIPTION_MODE == \"vosk\":\n",
    "                        vosk_reset_requested = True\n",
    "\n",
    "        # ---- COLLECT AUDIO FOR ASR ----\n",
    "        if state in (\"SPEAKING\", \"PAUSING\"):\n",
    "            with asr_lock:\n",
    "                if TRANSCRIPTION_MODE == \"vosk\":\n",
    "                    # For Vosk: accumulate full chunks\n",
    "                    if not hasattr(asr_worker, \"vosk_buf\"):\n",
    "                        asr_worker.vosk_buf = np.zeros(0, dtype=np.float32)\n",
    "                    asr_worker.vosk_buf = np.concatenate([asr_worker.vosk_buf, frame])\n",
    "                    \n",
    "                    # Feed Vosk in 0.2s+ chunks\n",
    "                    while len(asr_worker.vosk_buf) >= VOSK_MIN_SAMPLES:\n",
    "                        chunk_to_send = asr_worker.vosk_buf[:VOSK_MIN_SAMPLES]\n",
    "                        asr_worker.vosk_buf = asr_worker.vosk_buf[VOSK_MIN_SAMPLES:]\n",
    "                        asr_audio.append((chunk_to_send.copy(), now))\n",
    "                else:\n",
    "                    # For Whisper: stream all frames\n",
    "                    asr_audio.append((frame.copy(), now))\n",
    "                    # Trim old frames beyond window\n",
    "                    cutoff = now - WHISPER_WINDOW_SEC\n",
    "                    while asr_audio and asr_audio[0][1] < cutoff:\n",
    "                        asr_audio.popleft()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    stream.stop()\n",
    "    print(\"\\nğŸ›‘ Test stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d28816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interactive-chat-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
